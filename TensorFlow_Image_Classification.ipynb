{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabrielnkl/notebooks/blob/main/TensorFlow_Image_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzJu9Sf0Niau"
      },
      "source": [
        "# Image Classification with TensorFlow: From Classical ML to Deep Learning\n",
        "\n",
        "This notebook covers:\n",
        "- Baseline Model (Without Deep Learning)\n",
        "- CNN Model from Scratch\n",
        "- Transfer Learning\n",
        "- Fine-tuning Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOpYsg56Niav"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow scikit-learn tensorflow-datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b_wH4pJFNiaw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPS0gkGxNiax"
      },
      "source": [
        "## Load and preprocess CIFAR-10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "90b2e0bd170141ae8b16bd5505ae60ef",
            "b9831f4ba92a46fbb9ea8917f969eb33",
            "3d55ab4ea70c4f6182949072522dc73f",
            "336b4d679c454c0db9e23bf7a54db4db",
            "3c4acc5f5c9a4aeabab883a9096f4ac7",
            "51428c5184884c6f9309b258fd15e782",
            "34476eed63b240deb702f32b72770f19",
            "ef6f0575db1347c4a168ae3a636f4766",
            "a936018d02b140b6831183ff2eb2a2d6",
            "5de742e49fef44d5b3fea470def0ea1d",
            "071bd685197e45c78614efcca7959b53",
            "c4fb9ee904c74096ba699856bcc7e01f",
            "ab5aec489abc4cbf8541c8abb484da52",
            "133b8e82586148cf86913d5171618277",
            "e99ead7c9f9f4fddb260189ed94cf0c1",
            "f776dac94c3345d9840a9b120eb152d2",
            "bfe9fdfb456142809f7a83e3822ac443",
            "988cafb25fc84b37803459aa1e3957e2",
            "6df57a81ab2b4b258db4ce26ac92ab50",
            "dbd54616e1b7458687d1b6b490990d04",
            "5f164fd3ed924e53a7897c19aacce362",
            "797031287d73498bbb7730452dd425bc",
            "7ede6be9115f450fbeb06e8302dd3812",
            "597cc9d781cd4d1ca4e7d7f8dc296eca",
            "1cc29780772b42959738f4776f09ac18",
            "d1bdd4175e65466782bdc1b9a1b4c352",
            "aab388b724a545999aa40964e5d5bf9a",
            "c02205b70d0940e28df7ea9524d80be2",
            "6192f4b23dfa4070bec63b3f9d86511c",
            "743be53b202a47b099668e08b3ebf3c1",
            "94e3c9dfad1045c0852c247a9b9950f0",
            "8142c58572a749dda168a770436f1c0a",
            "c7c24d1f2c8f49a1a3622768f3d87a25",
            "b4505e7fc8154a01ac1acf91cd3c70d8",
            "eb88162f570443cf936d85c9394c74f0",
            "d212f526387c4168a56e5aeece137db6",
            "835445990da64e6ca1431aa0301f0a4f",
            "33bd748319904234a2989186d0f906ab",
            "160dae38779e4e1c88f3d43384ffd931",
            "b97e2a7769c54dbe8779345e80e731ba",
            "8286798e05134e0aac8c90029abfaff0",
            "926c630f28674e5b8d43ab1ce38970a9",
            "e7ada583e0824eda88338831d716bc3a",
            "5ca0be07580d40b3aa4abd476114ff64",
            "0a5bc8e060f049a981b3795b01c4b435",
            "101f892bdf90480fa38e9a9a8f7f527f",
            "f8df0b9462d7439f977122d75c4807e5",
            "114f6ef7b63e4dd494c11c633d00f741",
            "b5e4bec5ce414bd78cac3347659fcc1f",
            "6220a8307fa4431d9c79cd0cd8ec3dcd",
            "0f05559e2ff94c289c81b7c89cdb32b5",
            "84ad8dc2a6b64bd296e55d06bd156476",
            "c601353e64e14579b3a54f7b21531902",
            "498a08c1e8244ec495021f96dc5521ad",
            "41bd7fd2111b47bc9d0eef7005364a1c",
            "88691961563d446c82145ed0d7f2f800",
            "a09f6cd2bde547a1919ae4f2511fb992",
            "69ecc269ff5c455186dd2a5ff52ad6f1",
            "12ff92cfaf5a4fde988b8fb8152de368",
            "bf6af0b45ae447278fa43c0343f2b2ce",
            "bb945767c66346fa979c0537473d3566",
            "98c88aedeb1a4ae4a58907922dc1df72",
            "ad1c15e589404e0dabd9d3fbc0988ce0",
            "5c2a0f0440b0466c808687f723226a45",
            "37ccfc2e3a77436aa8c68877803f65b4",
            "033a2b6d59fa4344865b83c1757524ba",
            "d4786bc7e4284af0b6b6b90f2fa4aa59",
            "06ca5c36fa10456f81d2762e851c2adc",
            "2dde49c2c06b43ec9399c9e22630dc1c",
            "2d7218e2712444a485c2b97b83dec31d",
            "b1a047bab8704090949e3a7556e018ab",
            "ab99ea799eff41899fcb03dc249b568c",
            "6956638817c444a0b6936584a91e704c",
            "cae4d12f88bd442d904cbd5fb6dfa9d9",
            "f2ee4a5de6cb4d94a42c95e6448fc692",
            "51a27758b55b49c88219c8d52139f3f8",
            "d602bd5dafb04e148b09dae6e809dfbf",
            "b91f10ea04194a7cb46d9e11d158c4ba",
            "e76aec6490a44f84959834a53d0677a7",
            "ddaf39e182cf40f3abf8dae11f3f32c7",
            "5897d0efa1524074954dd31b48a03e72",
            "f0ce1aa524ac43c687275b1f43891d1f",
            "5f279fe792c7436fad1ea9b65ff5591f",
            "0392105038a14dae9e1182452c47fc68",
            "b1760ca1908c463bb122ddd6c613ac37",
            "4feef229429e46bbbf73ef3f80c7ae8f",
            "763c88b0071748ad9663b2b4ab51723e",
            "f2f64e17a19e488c921b84de221840d7"
          ]
        },
        "id": "xk_Dt3vsNiax",
        "outputId": "a1275664-9566-4135-86f1-f189423b7365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Variant folder /root/tensorflow_datasets/cifar10/3.0.2 has no dataset_info.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /root/tensorflow_datasets/cifar10/3.0.2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90b2e0bd170141ae8b16bd5505ae60ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4fb9ee904c74096ba699856bcc7e01f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ede6be9115f450fbeb06e8302dd3812"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4505e7fc8154a01ac1acf91cd3c70d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train examples...: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a5bc8e060f049a981b3795b01c4b435"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/cifar10/incomplete.JHVKC8_3.0.2/cifar10-train.tfrecord*...:   0%|         …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88691961563d446c82145ed0d7f2f800"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test examples...: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4786bc7e4284af0b6b6b90f2fa4aa59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Shuffling /root/tensorflow_datasets/cifar10/incomplete.JHVKC8_3.0.2/cifar10-test.tfrecord*...:   0%|          …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b91f10ea04194a7cb46d9e11d158c4ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cifar10 downloaded and prepared to /root/tensorflow_datasets/cifar10/3.0.2. Subsequent calls will reuse this data.\n"
          ]
        }
      ],
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    \"cifar10\",\n",
        "    split=[\"train\", \"test\"],\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, (32, 32))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "ds_train = ds_train.map(preprocess).shuffle(1000).batch(BATCH_SIZE)\n",
        "ds_test = ds_test.map(preprocess).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhz5huZ5Niax"
      },
      "source": [
        "## 1. Baseline Model (Without Deep Learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "dBP-qu2-Niay",
        "outputId": "7cbc21aa-770e-4a7c-d3b9-03ef123ae8e9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (782,) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-86853ae39c4f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (782,) + inhomogeneous part."
          ]
        }
      ],
      "source": [
        "X_train, y_train = [], []\n",
        "for img, label in tfds.as_numpy(ds_train):\n",
        "    X_train.append(img.reshape(-1))\n",
        "    y_train.append(label)\n",
        "\n",
        "X_test, y_test = [], []\n",
        "for img, label in tfds.as_numpy(ds_test):\n",
        "    X_test.append(img.reshape(-1))\n",
        "    y_test.append(label)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "baseline_model = LogisticRegression(max_iter=100)\n",
        "baseline_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = baseline_model.predict(X_test)\n",
        "\n",
        "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "source": [
        "X_train, y_train = [], []\n",
        "for img_batch, label_batch in tfds.as_numpy(ds_train):\n",
        "    # Iterate over individual images and labels within the batch\n",
        "    for img, label in zip(img_batch, label_batch):\n",
        "        X_train.append(img.reshape(-1))\n",
        "        y_train.append(label)\n",
        "\n",
        "X_test, y_test = [], []\n",
        "for img_batch, label_batch in tfds.as_numpy(ds_test):\n",
        "    # Iterate over individual images and labels within the batch\n",
        "    for img, label in zip(img_batch, label_batch):\n",
        "        X_test.append(img.reshape(-1))\n",
        "        y_test.append(label)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "baseline_model = LogisticRegression(max_iter=100)\n",
        "baseline_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = baseline_model.predict(X_test)\n",
        "\n",
        "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtiejSyuOakh",
        "outputId": "f6106bf1-4cb7-40e6-c8e8-879d2772d12d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy: 0.4051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ePneRMLNiay"
      },
      "source": [
        "## 2. CNN Model from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO8fKFLWNiay",
        "outputId": "06b881e5-bd1d-49c5-a741-7837bb992703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.3826 - loss: 1.6943 - val_accuracy: 0.5771 - val_loss: 1.1938\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.5949 - loss: 1.1578 - val_accuracy: 0.6318 - val_loss: 1.0556\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.6535 - loss: 0.9955 - val_accuracy: 0.6675 - val_loss: 0.9652\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6926 - loss: 0.8945 - val_accuracy: 0.6736 - val_loss: 0.9352\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7207 - loss: 0.8129 - val_accuracy: 0.6852 - val_loss: 0.9137\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7420 - loss: 0.7404 - val_accuracy: 0.6903 - val_loss: 0.9097\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7656 - loss: 0.6685 - val_accuracy: 0.6942 - val_loss: 0.9238\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.7902 - loss: 0.6059 - val_accuracy: 0.6919 - val_loss: 0.9358\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.8125 - loss: 0.5396 - val_accuracy: 0.6943 - val_loss: 0.9733\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8322 - loss: 0.4828 - val_accuracy: 0.7009 - val_loss: 0.9753\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eeb44213a90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "cnn_model = Sequential([\n",
        "    layers.Input(shape=(32, 32, 3)),\n",
        "    layers.Conv2D(32, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 3, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "cnn_model.fit(ds_train, epochs=10, validation_data=ds_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k00duc2aNiaz"
      },
      "source": [
        "## 3. Transfer Learning (Feature Extraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BproSDVmNiaz",
        "outputId": "52e332fd-fa61-4afa-fef4-4f7ad826cb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 30ms/step - accuracy: 0.1004 - loss: 2.3401 - val_accuracy: 0.1000 - val_loss: 2.3027\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 20ms/step - accuracy: 0.0974 - loss: 2.3028 - val_accuracy: 0.1000 - val_loss: 2.3026\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.0983 - loss: 2.3027 - val_accuracy: 0.1000 - val_loss: 2.3026\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.0984 - loss: 2.3028 - val_accuracy: 0.1000 - val_loss: 2.3026\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.0982 - loss: 2.3027 - val_accuracy: 0.1000 - val_loss: 2.3026\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eeb444c4e50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(96, 96, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "def preprocess_mobilenet(image, label):\n",
        "    image = tf.image.resize(image, (96, 96))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "ds_train_mobilenet = ds_train.map(preprocess_mobilenet)\n",
        "ds_test_mobilenet = ds_test.map(preprocess_mobilenet)\n",
        "\n",
        "model_transfer = Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_transfer.compile(optimizer='adam',\n",
        "                        loss='sparse_categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "model_transfer.fit(ds_train_mobilenet, epochs=5, validation_data=ds_test_mobilenet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86tPV4P5Niaz"
      },
      "source": [
        "## 4. Fine-Tuning the Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmOpNuCyNiaz",
        "outputId": "b65628c8-de04-4c91-a2c4-37db8ae3dbbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 88ms/step - accuracy: 0.3409 - loss: 1.8949 - val_accuracy: 0.1000 - val_loss: 2.5275\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 53ms/step - accuracy: 0.7351 - loss: 0.7870 - val_accuracy: 0.0995 - val_loss: 2.5636\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 54ms/step - accuracy: 0.8132 - loss: 0.5492 - val_accuracy: 0.1008 - val_loss: 2.5581\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 54ms/step - accuracy: 0.8545 - loss: 0.4283 - val_accuracy: 0.0999 - val_loss: 2.5333\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 54ms/step - accuracy: 0.8854 - loss: 0.3426 - val_accuracy: 0.1014 - val_loss: 2.8769\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7eeb301c32d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "model_transfer.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
        "                       loss='sparse_categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "model_transfer.fit(ds_train_mobilenet, epochs=5, validation_data=ds_test_mobilenet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVCCgt62Nia0"
      },
      "source": [
        "## Results Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLF3UFYTNia0",
        "outputId": "1fba8614-ee30-47bd-910d-69c6d995e1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6987 - loss: 0.9820\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.1033 - loss: 2.8581\n",
            "Baseline Accuracy: 0.41\n",
            "CNN Accuracy: 0.70\n",
            "Transfer Learning Accuracy: 0.10\n"
          ]
        }
      ],
      "source": [
        "cnn_loss, cnn_acc = cnn_model.evaluate(ds_test)\n",
        "transfer_loss, transfer_acc = model_transfer.evaluate(ds_test_mobilenet)\n",
        "\n",
        "print(f\"Baseline Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "print(f\"CNN Accuracy: {cnn_acc:.2f}\")\n",
        "print(f\"Transfer Learning Accuracy: {transfer_acc:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
